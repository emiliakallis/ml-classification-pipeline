{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3efda0c8",
   "metadata": {},
   "source": [
    "# Maximizing Predictive Performance in ML Classification Tasks\n",
    "\n",
    "This notebook presents a complete ML pipeline to compare and optimize classification models on a structured dataset.\n",
    "\n",
    "A dataset is explored to find the best machine learning model for predicting the target variable `y`. It includes data loading, preprocessing, model training, cross-validation, and performance evaluation for various algorithms.\n",
    "\n",
    "The goal is to demonstrate effective model comparison and reasoning in selecting the best-performing model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8decf3a",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "This notebook requires the following Python packages:\n",
    "\n",
    "| Library        | Alias | Purpose                      |\n",
    "|----------------|-------|------------------------------|\n",
    "| `pandas`       | `pd`  | Data manipulation            |\n",
    "| `numpy`        | `np`  | Numerical operations         |\n",
    "| `scikit-learn` | —     | ML models, preprocessing     |\n",
    "| `matplotlib`   | `plt` | Plotting                     |\n",
    "| `seaborn`      | `sns` | Visualization                |\n",
    "| `optuna`       | —     | Hyperparameter tuning        |\n",
    "| `xgboost`      | —     | Boosting classifiers         |\n",
    "| `lightgbm`     | —     | Boosting classifiers         |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd14814e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell in Google Colab or fresh environments\n",
    "!pip install pandas numpy scikit-learn matplotlib seaborn optuna xgboost lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ed45a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import optuna\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from optuna.integration import XGBoostPruningCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ac53c5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "ZjRoXSIcxaPP",
    "outputId": "32b7ebc5-4857-42d3-a1b2-195a5d45bb46"
   },
   "outputs": [],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1d68c0",
   "metadata": {},
   "source": [
    "## 1. Data Access via Google Drive\n",
    "\n",
    "To work with the dataset in a Google Colab environment, I first mount Google Drive.  \n",
    "This allows me to access files stored in a personal Google Drive folder.\n",
    "\n",
    "> Note: If you're running this notebook locally, replace the Drive path with a local file path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a826f25",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ztYA2e296O38",
    "outputId": "b78d77fc-34b4-4d88-c105-573f859218d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3998f07c",
   "metadata": {
    "id": "qBikSHqe-zbV"
   },
   "outputs": [],
   "source": [
    "# Update this path to match your Google Drive folder structure\n",
    "data_path = \"path/to/your/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8428a59e",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "\n",
    "In this section, I load the dataset into a pandas DataFrame.\n",
    "\n",
    "The data is assumed to be in `.csv` format and stored either in Google Drive (for Colab users) or locally (for offline use).\n",
    "\n",
    "> Tip: Ensure the dataset file name is correct and that the file is uploaded or accessible from your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0316aa75",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "igbd_y906JL1",
    "outputId": "50c42918-a7f8-46c2-a1a9-74369941a83d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           y         x1       x2         x3       x4         x5         x6  \\\n",
      "0  Antrophic  199.84675 -0.22935  -94.57266 -0.90297  229.65733 -119.73784   \n",
      "1     OpenAI  199.76663  0.57961  -98.69548 -0.89087  229.58771 -117.92856   \n",
      "2  Antrophic  200.40804 -0.03834  -97.64719 -0.89971  230.20797 -121.71234   \n",
      "3  Antrophic  201.38523  0.51942 -105.16820 -0.89226  231.15781 -120.69422   \n",
      "4     OpenAI  199.60130 -0.76663  -94.42670 -0.88284  229.39822 -122.24543   \n",
      "\n",
      "   x7       x8       x9       x10      x11   x12        x13  \n",
      "0  Q4  0.12045  0.50670  13.31960  2.86055  True  951.94743  \n",
      "1  Q4 -0.28505  0.16832  14.52734 -0.51453  True  949.48540  \n",
      "2  Q3 -0.13753  0.71530   9.90651  0.35612  True  953.21660  \n",
      "3  Q2  0.03872 -0.37550  11.10684  1.32156  True  954.34203  \n",
      "4  Q4  0.46721  2.14220   9.72683 -4.96100  True  950.79316  \n",
      "Index(['y', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10', 'x11',\n",
      "       'x12', 'x13'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Read CSV while skipping the first column\n",
    "df = pd.read_csv(data_path + \"TrainOnMe.csv\", index_col=0)  # Drops the first column\n",
    "\n",
    "# Preview the data\n",
    "print(df.head())\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9aa562",
   "metadata": {},
   "source": [
    "## 3. Initial Preprocessing\n",
    "\n",
    "In this step, I prepare the dataset for modeling by transforming categorical and binary variables, separating features from the target, and standardizing the inputs.\n",
    "\n",
    "These preprocessing steps are essential to ensure that the machine learning models receive clean, properly formatted data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d7711a",
   "metadata": {
    "id": "SLP6M3UB_Wbq"
   },
   "outputs": [],
   "source": [
    "# Identify categorical and binary columns (excluding the target 'y')\n",
    "categorical_col = 'x7'\n",
    "binary_col = 'x12'  # Binary column\n",
    "\n",
    "# Separate target variable from features\n",
    "y = df['y']\n",
    "X = df.drop(columns=['y'])\n",
    "\n",
    "# Convert binary column (True/False) to integers (1/0)\n",
    "X[binary_col] = X[binary_col].astype(int)\n",
    "\n",
    "# One-hot encode the categorical feature (x7)\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "encoded_X = encoder.fit_transform(X[['x7']])\n",
    "encoded_X_df = pd.DataFrame(encoded_X, columns=encoder.get_feature_names_out(['x7']))\n",
    "\n",
    "# Drop original categorical column and add encoded features\n",
    "X = X.drop(columns=['x7']).reset_index(drop=True)\n",
    "X = pd.concat([X, encoded_X_df], axis=1)\n",
    "\n",
    "# Label-encode the target variable 'y' for classification\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821a0e5f",
   "metadata": {
    "id": "d8zp0TX4jsYF"
   },
   "outputs": [],
   "source": [
    "# Standardize numerical features (after encoding is complete)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d762d1b",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering & Splitting\n",
    "After preprocessing, I split the dataset into training and test sets using stratified sampling to preserve the class distribution.\n",
    "\n",
    "I also visualize the class balance in the training data, which is an important step before applying any resampling techniques (e.g., SMOTE) or training models.\n",
    "\n",
    "> Class imbalance, if present, can impact model performance and must be handled appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ea3f23",
   "metadata": {
    "id": "RvTvZLhCjy81"
   },
   "outputs": [],
   "source": [
    "# Split the data into training and test sets (80/20 split), stratifying by target class\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b9c03c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "5xUD-8C48vZn",
    "outputId": "13e9a6f1-9219-4e71-fcbd-d566724526db"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize class distribution in the training set\n",
    "sns.countplot(x=y_train)\n",
    "plt.title(\"Class Distribution Before SMOTE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd0024c",
   "metadata": {},
   "source": [
    "## 5. Hyperparameter Optimization for Classifiers\n",
    "\n",
    "I define and optimize three classification models: **Random Forest**, **XGBoost**, and **LightGBM**.\n",
    "\n",
    "Using `Optuna`, I tune each model’s hyperparameters to maximize classification accuracy. Each optimization uses cross-validation for evaluation, and pruning is enabled to efficiently skip unpromising trials.\n",
    "\n",
    "> This approach demonstrates practical experience in model selection, tuning, and reproducibility in real-world ML workflows.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85096332",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_jxTyMs4tFx3",
    "outputId": "106df53a-d8f3-4dc2-ffc7-22f9f4539268"
   },
   "outputs": [],
   "source": [
    "# Random Forest Objective Function for Optuna\n",
    "def rf_objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 600, step=50)\n",
    "    max_depth = trial.suggest_int('max_depth', 5, 30, step=2)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\n",
    "    bootstrap = trial.suggest_categorical('bootstrap', [True, False])\n",
    "\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features,\n",
    "        bootstrap=bootstrap,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    return cross_val_score(rf, X_train, y_train, cv=10, scoring='accuracy').mean()\n",
    "\n",
    "# Run Optuna study for RF\n",
    "rf_study = optuna.create_study(direction=\"maximize\")\n",
    "rf_study.optimize(rf_objective, n_trials=50, n_jobs=-1)\n",
    "\n",
    "print(\"Best RF Parameters:\", rf_study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66de9661",
   "metadata": {},
   "source": [
    "### Best Random Forest Parameters (Optuna Result)\n",
    "\n",
    "- `n_estimators`: 600  \n",
    "- `max_depth`: 15  \n",
    "- `min_samples_split`: 12  \n",
    "- `min_samples_leaf`: 2  \n",
    "- `max_features`: \"log2\"  \n",
    "- `bootstrap`: True  \n",
    "- **Cross-validated Accuracy**: 0.68750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe1ba80",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VbP52rt1tPgf",
    "outputId": "30a11c88-95ce-4a5d-8875-ce4933ecdecf"
   },
   "outputs": [],
   "source": [
    "# XGBoost Objective Function for Optuna\n",
    "def xgb_objective(trial):\n",
    "    pruning_callback = XGBoostPruningCallback(trial, \"validation_0-logloss\")\n",
    "\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 500, step=50)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 15)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3)\n",
    "    subsample = trial.suggest_float('subsample', 0.6, 1.0)\n",
    "    colsample_bytree = trial.suggest_float('colsample_bytree', 0.6, 1.0)\n",
    "    gamma = trial.suggest_float('gamma', 0, 5)\n",
    "\n",
    "    xgb = XGBClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        gamma=gamma,\n",
    "        random_state=42,\n",
    "        eval_metric=\"logloss\",\n",
    "        tree_method=\"gpu_hist\",  # GPU acceleration\n",
    "        gpu_id=0\n",
    "    )\n",
    "\n",
    "    scores = cross_val_score(xgb, X_train, y_train, cv=3, scoring=\"accuracy\")\n",
    "\n",
    "    trial.report(scores.mean(), step=0)\n",
    "\n",
    "    if trial.should_prune():\n",
    "        raise optuna.TrialPruned()\n",
    "\n",
    "    return scores.mean()\n",
    "\n",
    "# Run Optuna study for XGBoost\n",
    "xgb_study = optuna.create_study(direction=\"maximize\", pruner=optuna.pruners.MedianPruner(n_warmup_steps=5))\n",
    "xgb_study.optimize(xgb_objective, n_trials=30, n_jobs=-1)\n",
    "\n",
    "print(\"Best XGB Parameters:\", xgb_study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ef8972",
   "metadata": {},
   "source": [
    "### Best XGBoost Parameters (Optuna Result)\n",
    "\n",
    "- `n_estimators`: 550  \n",
    "- `max_depth`: 8  \n",
    "- `learning_rate`: 0.2051686949233296\n",
    "- `subsample`: 0.5060864147463304\n",
    "- `colsample_bytree`: 0.8061335924872397\n",
    "- `gamma`: 4.069312272904837\n",
    "- **Cross-validated Accuracy**: 0.69025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a986dd8f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mGWjo6g0tUhB",
    "outputId": "8a645dcf-9132-4c5d-fb34-7c0ac351d8fc"
   },
   "outputs": [],
   "source": [
    "# LightGBM Objective Function for Optuna\n",
    "def lgb_objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 300, step=50)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.2)\n",
    "    num_leaves = trial.suggest_int('num_leaves', 20, 100)  # Reduced range\n",
    "    min_child_samples = trial.suggest_int('min_child_samples', 5, 50)  # Smaller range\n",
    "    lambda_l1 = trial.suggest_float('lambda_l1', 0, 2)  # Reduced range\n",
    "    lambda_l2 = trial.suggest_float('lambda_l2', 0, 2)\n",
    "\n",
    "    lgb = LGBMClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        learning_rate=learning_rate,\n",
    "        num_leaves=num_leaves,\n",
    "        min_child_samples=min_child_samples,\n",
    "        lambda_l1=lambda_l1,\n",
    "        lambda_l2=lambda_l2,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    return cross_val_score(lgb, X_train, y_train, cv=5, scoring='accuracy').mean()  # 5-Fold CV for speed\n",
    "\n",
    "# Run Optuna study for LGBM\n",
    "pruner = optuna.pruners.MedianPruner(n_warmup_steps=5)\n",
    "lgb_study = optuna.create_study(direction=\"maximize\", pruner=pruner)\n",
    "lgb_study.optimize(lgb_objective, n_trials=30, n_jobs=-1)\n",
    "\n",
    "print(\"Best LGB Parameters:\", lgb_study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc74748",
   "metadata": {},
   "source": [
    "### Best LightGBM Parameters (Optuna Result)\n",
    "\n",
    "- `n_estimators`: 100   \n",
    "- `learning_rate`: 0.021759151111545517\n",
    "- `num_leaves`: 42\n",
    "- `min_child_samples`: 18\n",
    "- `lambda_l1`: 0.3271237462768151\n",
    "- `lambda_l2`: 0.8711423014282733\n",
    "- **Cross-validated Accuracy**: 0.67950"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97de691",
   "metadata": {},
   "source": [
    "## 6. Stacked Ensemble Evaluation (Model Comparison)\n",
    "\n",
    "In this section, I compare various final estimators within a stacked ensemble using optimized base models:\n",
    "\n",
    "- Base models: tuned **Random Forest**, **XGBoost**, and **LightGBM**\n",
    "- Final estimators tested: **Logistic Regression**, **XGBoost**, **Random Forest**, and **LightGBM**\n",
    "\n",
    "Each stacking configuration is evaluated using accuracy on the test set.  \n",
    "This comparison helps identify which final estimator performs best before selecting a final ensemble.\n",
    "\n",
    "> The selected configuration in the next section is used to make final predictions on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0bbf72",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "0_dGm7YDrRzl",
    "outputId": "23a075ed-0fdb-4806-e2c9-91c5eb522a1f"
   },
   "outputs": [],
   "source": [
    "# Initialize base models using best hyperparameters found via Optuna\n",
    "best_rf = RandomForestClassifier(**rf_study.best_params, random_state=42)\n",
    "best_xgb = XGBClassifier(**xgb_study.best_params, random_state=42, eval_metric=\"logloss\")\n",
    "best_lgb = LGBMClassifier(**lgb_study.best_params, random_state=42)\n",
    "\n",
    "# Define different models to test as the final estimator in a stacking ensemble\n",
    "final_estimators = {\n",
    "    \"LogisticRegression\": LogisticRegression(),\n",
    "    \"XGBoost\": XGBClassifier(n_estimators=100, learning_rate=0.05, random_state=42),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42),\n",
    "    \"LightGBM\": LGBMClassifier(n_estimators=100, learning_rate=0.05, random_state=42),\n",
    "}\n",
    "\n",
    "# Evaluate each stacking configuration with different final estimators\n",
    "for name, estimator in final_estimators.items():\n",
    "    # Create stacking classifier with fixed base models and a variable final estimator\n",
    "    stacking_model = StackingClassifier(\n",
    "        estimators=[('rf', best_rf), ('xgb', best_xgb), ('lgb', best_lgb)],\n",
    "        final_estimator=estimator,\n",
    "        cv=5\n",
    "    )\n",
    "    \n",
    "    # Train the stacking model\n",
    "    stacking_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set and evaluate accuracy\n",
    "    y_pred = stacking_model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Stacking Accuracy with {name}: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9ce9e3",
   "metadata": {},
   "source": [
    "### Stacked Ensemble Results\n",
    "\n",
    "I evaluated different final estimators for a stacking classifier using cross-validated accuracy:\n",
    "\n",
    "<table>\n",
    "<tr><td><code>LogisticRegression</code></td><td><strong>0.7040</strong></td></tr>\n",
    "<tr><td><code>RandomForest</code></td><td><strong>0.7010</strong></td></tr>\n",
    "<tr><td><code>XGBoost</code></td><td><strong>0.6930</strong></td></tr>\n",
    "<tr><td><code>LightGBM</code></td><td><strong>0.6880</strong></td></tr>\n",
    "</table>\n",
    "&nbsp;\n",
    "\n",
    "> Based on this evaluation, I selected **LogisticRegression** as the final estimator for the stacking model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83c93d7",
   "metadata": {},
   "source": [
    "## 7. Final Ensemble Selection & Evaluation\n",
    "\n",
    "Based on the model comparison in Section 6, I select the final stacking model with `LogisticRegression` as the final estimator.\n",
    "\n",
    "I retrain the stacking ensemble on the full training data and evaluate its accuracy on the test set to finalize my model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fa503e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ql_Q0vAbtYUv",
    "outputId": "244cb321-0e58-4159-d1b0-1e13c4a0cede"
   },
   "outputs": [],
   "source": [
    "# Define final stacking model using Logistic Regression as final estimator\n",
    "final_stacking = StackingClassifier(\n",
    "    estimators=[('rf', best_rf), ('xgb', best_xgb), ('lgb', best_lgb)],\n",
    "    final_estimator=LogisticRegression(),\n",
    "    cv=10\n",
    ")\n",
    "\n",
    "# Train the final ensemble on the full training set\n",
    "final_stacking.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate final model on test set\n",
    "y_pred = final_stacking.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Final Stacking Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d0c641",
   "metadata": {},
   "source": [
    "## 8. Predicting on New Data\n",
    "\n",
    "In this section, I use the final trained stacking model to make predictions on unseen data (`EvaluateOnMe.csv`).\n",
    "\n",
    "The new data undergoes the same preprocessing pipeline as the training data.  \n",
    "The output predictions are saved as a CSV file for downstream use, emulating a real-world model deployment pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a72ce76",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YtCvq_hNLRil",
    "outputId": "cd619f6e-f7c3-4867-9096-9f8ed77f15a5"
   },
   "outputs": [],
   "source": [
    "# Load unseen test data\n",
    "new_data = pd.read_csv(data_path + \"EvaluateOnMe.csv\", index_col=0)\n",
    "\n",
    "# Preprocess new data using the same steps as training data\n",
    "\n",
    "# Encode binary column (True/False → 1/0)\n",
    "new_data[binary_col] = new_data[binary_col].astype(int)\n",
    "\n",
    "# One-hot encode the categorical column (x7)\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "encoded_new_data = encoder.fit_transform(new_data[['x7']])\n",
    "encoded_new_data = pd.DataFrame(encoded_new_data, columns=encoder.get_feature_names_out(['x7']))\n",
    "\n",
    "# Replace original categorical column with one-hot version\n",
    "new_data = new_data.drop(columns=['x7']).reset_index(drop=True)\n",
    "new_data = pd.concat([new_data, encoded_new_data], axis=1)\n",
    "\n",
    "# Apply standard scaling to match training distribution\n",
    "scaler = StandardScaler()\n",
    "new_data_scaled = scaler.fit_transform(new_data)\n",
    "\n",
    "# Generate predictions\n",
    "predicted_labels_encoded = final_stacking.predict(new_data_scaled)\n",
    "predicted_labels = label_encoder.inverse_transform(predicted_labels_encoded)\n",
    "\n",
    "# Save predictions as a CSV file\n",
    "pd.DataFrame(predicted_labels).to_csv(\"predictions.csv\", index=False, header=False)\n",
    "\n",
    "print(\"Predictions saved as predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec32926a",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "\n",
    "This notebook demonstrated a full machine learning classification workflow:\n",
    "\n",
    "- Explored and preprocessed data with categorical and binary features\n",
    "- Tuned hyperparameters for **Random Forest**, **XGBoost**, and **LightGBM** using `Optuna`\n",
    "- Compared stacked ensemble performance with multiple final estimators\n",
    "- Selected a final stacking model with **Logistic Regression** based on test accuracy\n",
    "- Applied the trained model to make predictions on unseen data\n",
    "\n",
    "> This end-to-end pipeline reflects a real-world ML workflow, balancing model performance, interpretability, and reproducibility.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
